{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>empty</td>\n",
       "      <td>xoshayzers</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habit earlier and i started freakin at his part =[</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>sadness</td>\n",
       "      <td>wannamama</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin on your call...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>sadness</td>\n",
       "      <td>coolfunky</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>czareaquino</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>neutral</td>\n",
       "      <td>xkilljoyx</td>\n",
       "      <td>@dannycastillo We want to trade with someone who has Houston tickets, but no one will.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39995</td>\n",
       "      <td>neutral</td>\n",
       "      <td>showMe_Heaven</td>\n",
       "      <td>@JohnLloydTaylor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39996</td>\n",
       "      <td>love</td>\n",
       "      <td>drapeaux</td>\n",
       "      <td>Happy Mothers Day  All my love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39997</td>\n",
       "      <td>love</td>\n",
       "      <td>JenniRox</td>\n",
       "      <td>Happy Mother's Day to all the mommies out there, be you woman or man as long as you're 'momma' to someone this is your day!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39998</td>\n",
       "      <td>happiness</td>\n",
       "      <td>ipdaman1</td>\n",
       "      <td>@niariley WASSUP BEAUTIFUL!!! FOLLOW ME!!  PEEP OUT MY NEW HIT SINGLES WWW.MYSPACE.COM/IPSOHOT I DEF. WAT U IN THE VIDEO!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>39999</td>\n",
       "      <td>love</td>\n",
       "      <td>Alpharalpha</td>\n",
       "      <td>@mopedronin bullet train from tokyo    the gf and i have been visiting japan since thursday  vacation/sightseeing    gaijin godzilla</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        sentiment         author  \\\n",
       "0      empty       xoshayzers      \n",
       "1      sadness     wannamama       \n",
       "2      sadness     coolfunky       \n",
       "3      enthusiasm  czareaquino     \n",
       "4      neutral     xkilljoyx       \n",
       "...        ...           ...       \n",
       "39995  neutral     showMe_Heaven   \n",
       "39996  love        drapeaux        \n",
       "39997  love        JenniRox        \n",
       "39998  happiness   ipdaman1        \n",
       "39999  love        Alpharalpha     \n",
       "\n",
       "                                                                                                                                    content  \n",
       "0      @tiffanylue i know  i was listenin to bad habit earlier and i started freakin at his part =[                                          \n",
       "1      Layin n bed with a headache  ughhhh...waitin on your call...                                                                          \n",
       "2      Funeral ceremony...gloomy friday...                                                                                                   \n",
       "3      wants to hang out with friends SOON!                                                                                                  \n",
       "4      @dannycastillo We want to trade with someone who has Houston tickets, but no one will.                                                \n",
       "...                                                                                       ...                                                \n",
       "39995  @JohnLloydTaylor                                                                                                                      \n",
       "39996  Happy Mothers Day  All my love                                                                                                        \n",
       "39997  Happy Mother's Day to all the mommies out there, be you woman or man as long as you're 'momma' to someone this is your day!           \n",
       "39998  @niariley WASSUP BEAUTIFUL!!! FOLLOW ME!!  PEEP OUT MY NEW HIT SINGLES WWW.MYSPACE.COM/IPSOHOT I DEF. WAT U IN THE VIDEO!!            \n",
       "39999  @mopedronin bullet train from tokyo    the gf and i have been visiting japan since thursday  vacation/sightseeing    gaijin godzilla  \n",
       "\n",
       "[40000 rows x 3 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(\"data/text_emotion.csv\")\n",
    "df = df.drop(columns = [\"tweet_id\"])\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "neutral       8638\n",
       "worry         8459\n",
       "happiness     5209\n",
       "sadness       5165\n",
       "love          3842\n",
       "surprise      2187\n",
       "fun           1776\n",
       "relief        1526\n",
       "hate          1323\n",
       "empty         827 \n",
       "enthusiasm    759 \n",
       "boredom       179 \n",
       "anger         110 \n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"sentiment\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save one without split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_txt(name, myseries):\n",
    "    myfile = open('data/{}.txt'.format(name), 'w')\n",
    "\n",
    "    for i, tweet in enumerate(myseries):\n",
    "        myfile.write(\"{} \\n\".format(tweet))\n",
    "\n",
    "    myfile.close()\n",
    "\n",
    "save_to_txt(\"tweets_full\", df[\"content\"])\n",
    "save_to_txt(\"tweets_full_target\", df[\"sentiment\"])\n",
    "save_to_txt(\"tweets_authors\", df[\"author\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split into train, valid and test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Create splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df[\"content\"], df[\"sentiment\"],\n",
    "                                                    test_size = 0.3 , shuffle=False)\n",
    "\n",
    "X_test, X_val, y_test, y_val = train_test_split(X_test, y_test, test_size=0.5, shuffle=False)\n",
    "\n",
    "# Assign the users to each sample\n",
    "tweet_users = df[\"author\"].to_numpy()\n",
    "users_train, users_test, users_val = tweet_users[:28000], tweet_users[28000:28000+6000], tweet_users[-6000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset length is 40000\n",
      "0    @tiffanylue i know  i was listenin to bad habit earlier and i started freakin at his part =[\n",
      "Name: content, dtype: object\n",
      "0    empty\n",
      "Name: sentiment, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(\"dataset length is \" + str(df.shape[0]))\n",
    "print(X_train.head(1))\n",
    "print(y_train.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_to_txt(name, myseries):\n",
    "    myfile = open('data/{}.txt'.format(name), 'w')\n",
    "\n",
    "    for i, tweet in enumerate(myseries):\n",
    "        myfile.write(\"{} \\n\".format(tweet))\n",
    "\n",
    "    myfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save tweets to txt  \n",
    "save_to_txt(\"tweets_train\", X_train)\n",
    "save_to_txt(\"tweets_test\", X_test)\n",
    "save_to_txt(\"tweets_val\", X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save targets to txt\n",
    "save_to_txt(\"targets_train\", y_train)\n",
    "save_to_txt(\"targets_test\", y_test)\n",
    "save_to_txt(\"targets_val\", y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save authors to txt    \n",
    "save_to_txt(\"authors_train\", users_train)\n",
    "save_to_txt(\"authors_test\", users_test)\n",
    "save_to_txt(\"authors_val\", users_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
